{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9f38baa",
   "metadata": {},
   "source": [
    "# Detecting Phishing URLs\n",
    "\n",
    "This code sets up a machine learning pipeline to detect phishing URLs by using natural language processing (NLP) and machine learning techniques.\n",
    "\n",
    "The purpose of this is to create a machine learning model to classify URLs as phishing or not. It preprocesses the text data (URLs) by tokenizing, stemming, and transforming it into a suitable format for the model, and then trains a model to predict whether a URL is a phishing attempt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0d336d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer # create sparse matrix of words using regexptokenizes  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report #gives whole info about matrices\n",
    "from sklearn.metrics import confusion_matrix #gives diff between actual and predict\n",
    "from sklearn.pipeline import make_pipeline # use for combining all prerocessors techniuqes and algos\n",
    "from nltk.tokenize import RegexpTokenizer # regexp tokenizers use to split words from text  \n",
    "from nltk.stem.snowball import SnowballStemmer # stemmes words\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e1d40d",
   "metadata": {},
   "source": [
    "Let's loads the dataset containing the phishing URLs and display a sample of 5 rows. As we can see the dataset contains a url and a label indicating whether the url is phishing (bad) or benign (good)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1347cee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>492691</th>\n",
       "      <td>93.183.155.22/limto1.tar</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466587</th>\n",
       "      <td>worthpoint.com/worthopedia/harold-lloyd-bebe-d...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434882</th>\n",
       "      <td>spiderbytes.com/ambientrance/deahs-gw.htm</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231609</th>\n",
       "      <td>profiles.lawyersdb.com/florida-venice/1099032-...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211329</th>\n",
       "      <td>markspoelstra.net/bio.html</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      URL Label\n",
       "492691                           93.183.155.22/limto1.tar   bad\n",
       "466587  worthpoint.com/worthopedia/harold-lloyd-bebe-d...  good\n",
       "434882          spiderbytes.com/ambientrance/deahs-gw.htm  good\n",
       "231609  profiles.lawyersdb.com/florida-venice/1099032-...  good\n",
       "211329                         markspoelstra.net/bio.html  good"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading dataset\n",
    "phishing_urls = pd.read_csv('data/phishing_site_urls.csv')\n",
    "phishing_urls.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2a70d90f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(549346, 2)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phishing_urls.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "891f75c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 549346 entries, 0 to 549345\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   URL     549346 non-null  object\n",
      " 1   Label   549346 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 8.4+ MB\n"
     ]
    }
   ],
   "source": [
    "phishing_urls.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8d938a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>392924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bad</th>\n",
       "      <td>156422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count\n",
       "Label        \n",
       "good   392924\n",
       "bad    156422"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts = pd.DataFrame(phishing_urls.Label.value_counts())\n",
    "label_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ea6f7b",
   "metadata": {},
   "source": [
    "### Using RegexpTokenizer\n",
    "The `RegexpTokenizer` is used to tokenize the URL text by splitting it into individual words based on a regular expression pattern. This step is essential for processing the URLs into a form that can be used for further analysis or machine learning.\n",
    "\n",
    "\n",
    "**`RegexpTokenizer(r'[A-Za-z]+')`**:\n",
    "   - Creates a tokenizer that splits the text into tokens consisting of alphabetic characters only (both uppercase and lowercase letters). The regular expression `[A-Za-z]+` matches sequences of letters.\n",
    "   - This is useful for focusing on the relevant textual information, ignoring numbers or special characters which may not provide valuable insights for phishing detection.\n",
    "\n",
    "Let's see how a url is before tokenization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6f4e7e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nobell.it/70ffb52d079109dca5664cce6f317373782/login.SkyPe.com/en/cgi-bin/verification/login/70ffb52d079109dca5664cce6f317373/index.php?cmd=_profile-ach&outdated_page_tmpl=p/gen/failed-to-load&nav=0.5.1&login_access=1322408526'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RegexpTokenizer\n",
    "#It is used in NLP for dividing paragraph into sentences and sentences to words\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'[A-Za-z]+')\n",
    "phishing_urls['URL'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c1d750",
   "metadata": {},
   "source": [
    "After applying the tokenization process, you can see that the URL has been broken down into individual alphabetic words.\n",
    "\n",
    "You can observe that:\n",
    "- The tokenizer has removed special characters (e.g., `://`, `.`) and only retained the alphabetic words.\n",
    "- This allows the model to focus on relevant textual content like \"phishing\" or \"page\" that might indicate a malicious URL.\n",
    "- The tokenized data can now be used for feature extraction or further preprocessing steps before training the machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ea2cc4e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nobell',\n",
       " 'it',\n",
       " 'ffb',\n",
       " 'd',\n",
       " 'dca',\n",
       " 'cce',\n",
       " 'f',\n",
       " 'login',\n",
       " 'SkyPe',\n",
       " 'com',\n",
       " 'en',\n",
       " 'cgi',\n",
       " 'bin',\n",
       " 'verification',\n",
       " 'login',\n",
       " 'ffb',\n",
       " 'd',\n",
       " 'dca',\n",
       " 'cce',\n",
       " 'f',\n",
       " 'index',\n",
       " 'php',\n",
       " 'cmd',\n",
       " 'profile',\n",
       " 'ach',\n",
       " 'outdated',\n",
       " 'page',\n",
       " 'tmpl',\n",
       " 'p',\n",
       " 'gen',\n",
       " 'failed',\n",
       " 'to',\n",
       " 'load',\n",
       " 'nav',\n",
       " 'login',\n",
       " 'access']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this will be pull letter which matches to expression\n",
    "tokenizer.tokenize(phishing_urls['URL'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "86d2034c",
   "metadata": {},
   "outputs": [],
   "source": [
    "phishing_urls['text_tokenized']=phishing_urls.URL.map(lambda t: tokenizer.tokenize(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bac5c9da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Label</th>\n",
       "      <th>text_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>353948</th>\n",
       "      <td>hometownusa.com/ut/Riverdale.html</td>\n",
       "      <td>good</td>\n",
       "      <td>[hometownusa, com, ut, Riverdale, html]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537065</th>\n",
       "      <td>bestsourcecode.com/fm9wn7</td>\n",
       "      <td>bad</td>\n",
       "      <td>[bestsourcecode, com, fm, wn]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494097</th>\n",
       "      <td>interface.xyzs.com/</td>\n",
       "      <td>bad</td>\n",
       "      <td>[interface, xyzs, com]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210216</th>\n",
       "      <td>m.espn.go.com/nfl/story?storyId=7269318&amp;e=RAD</td>\n",
       "      <td>good</td>\n",
       "      <td>[m, espn, go, com, nfl, story, storyId, e, RAD]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109631</th>\n",
       "      <td>portatilandaimes.com.br/chuky/inbox.htm</td>\n",
       "      <td>bad</td>\n",
       "      <td>[portatilandaimes, com, br, chuky, inbox, htm]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  URL Label  \\\n",
       "353948              hometownusa.com/ut/Riverdale.html  good   \n",
       "537065                      bestsourcecode.com/fm9wn7   bad   \n",
       "494097                            interface.xyzs.com/   bad   \n",
       "210216  m.espn.go.com/nfl/story?storyId=7269318&e=RAD  good   \n",
       "109631        portatilandaimes.com.br/chuky/inbox.htm   bad   \n",
       "\n",
       "                                         text_tokenized  \n",
       "353948          [hometownusa, com, ut, Riverdale, html]  \n",
       "537065                    [bestsourcecode, com, fm, wn]  \n",
       "494097                           [interface, xyzs, com]  \n",
       "210216  [m, espn, go, com, nfl, story, storyId, e, RAD]  \n",
       "109631   [portatilandaimes, com, br, chuky, inbox, htm]  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phishing_urls.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee4fd01",
   "metadata": {},
   "source": [
    "### Using Snowball Stemmer\n",
    "\n",
    "The **Snowball Stemmer** is used to reduce words to their root form (or \"stem\"). This helps in processing textual data by converting variations of a word into a common base form, which is useful for text analysis and machine learning tasks.\n",
    "\n",
    " **`SnowballStemmer(\"english\")`**:\n",
    "   - Initializes the **Snowball Stemmer** for the English language.\n",
    "   - The stemmer will reduce words like **\"university\"**, **\"universal\"**, and **\"universestar\"** to their common root word **\"univers\"**.\n",
    "   - It also removes common stop words (such as **\"of\"**, **\"and\"**, **\"is\"**, **\"was\"**, **\"are\"**, **\"I\"**) that do not contribute significant meaning in most contexts.\n",
    "\n",
    "The purpose of stemming is to simplify words by reducing them to their root form. This helps in handling variations of words and improving the efficiency of the machine learning model by focusing on the core meaning of the words rather than their different forms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66184e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "879ce277",
   "metadata": {},
   "outputs": [],
   "source": [
    "phishing_urls['text_stemmed'] = phishing_urls['text_tokenized'].map(lambda l: [stemmer.stem(word) for word in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c478275c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Label</th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>text_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46359</th>\n",
       "      <td>habbofontesangrenta.rel7.com/</td>\n",
       "      <td>bad</td>\n",
       "      <td>[habbofontesangrenta, rel, com]</td>\n",
       "      <td>[habbofontesangrenta, rel, com]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214267</th>\n",
       "      <td>mobiletechnology.dowjones.com/</td>\n",
       "      <td>good</td>\n",
       "      <td>[mobiletechnology, dowjones, com]</td>\n",
       "      <td>[mobiletechnolog, dowjon, com]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47177</th>\n",
       "      <td>www.hongtongsoft.com.cn/images/index.htm?us.ba...</td>\n",
       "      <td>bad</td>\n",
       "      <td>[www, hongtongsoft, com, cn, images, index, ht...</td>\n",
       "      <td>[www, hongtongsoft, com, cn, imag, index, htm,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426164</th>\n",
       "      <td>rubiconpress.org/books</td>\n",
       "      <td>good</td>\n",
       "      <td>[rubiconpress, org, books]</td>\n",
       "      <td>[rubiconpress, org, book]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403563</th>\n",
       "      <td>newadvent.org/cathen/11128a.htm</td>\n",
       "      <td>good</td>\n",
       "      <td>[newadvent, org, cathen, a, htm]</td>\n",
       "      <td>[newadv, org, cathen, a, htm]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      URL Label  \\\n",
       "46359                       habbofontesangrenta.rel7.com/   bad   \n",
       "214267                     mobiletechnology.dowjones.com/  good   \n",
       "47177   www.hongtongsoft.com.cn/images/index.htm?us.ba...   bad   \n",
       "426164                             rubiconpress.org/books  good   \n",
       "403563                    newadvent.org/cathen/11128a.htm  good   \n",
       "\n",
       "                                           text_tokenized  \\\n",
       "46359                     [habbofontesangrenta, rel, com]   \n",
       "214267                  [mobiletechnology, dowjones, com]   \n",
       "47177   [www, hongtongsoft, com, cn, images, index, ht...   \n",
       "426164                         [rubiconpress, org, books]   \n",
       "403563                   [newadvent, org, cathen, a, htm]   \n",
       "\n",
       "                                             text_stemmed  \n",
       "46359                     [habbofontesangrenta, rel, com]  \n",
       "214267                     [mobiletechnolog, dowjon, com]  \n",
       "47177   [www, hongtongsoft, com, cn, imag, index, htm,...  \n",
       "426164                          [rubiconpress, org, book]  \n",
       "403563                      [newadv, org, cathen, a, htm]  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phishing_urls.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a1a531",
   "metadata": {},
   "source": [
    "Here we want to convert the list of stemmed words back into a single string, which can be used in further text-based machine learning processes, such as feature extraction or model training. It ensures that the input data is in a format suitable for algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a7414cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#joining stemmed words\n",
    "phishing_urls['text_from_url'] = phishing_urls['text_stemmed'].map(lambda i:' '.join(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ebedebe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Label</th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>text_stemmed</th>\n",
       "      <th>text_from_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>319744</th>\n",
       "      <td>education.com/schoolfinder/us/virginia/staffor...</td>\n",
       "      <td>good</td>\n",
       "      <td>[education, com, schoolfinder, us, virginia, s...</td>\n",
       "      <td>[educ, com, schoolfind, us, virginia, stafford...</td>\n",
       "      <td>educ com schoolfind us virginia stafford grace...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351017</th>\n",
       "      <td>heraldscotland.com/sport/spl/aberdeen/glasgow-...</td>\n",
       "      <td>good</td>\n",
       "      <td>[heraldscotland, com, sport, spl, aberdeen, gl...</td>\n",
       "      <td>[heraldscotland, com, sport, spl, aberdeen, gl...</td>\n",
       "      <td>heraldscotland com sport spl aberdeen glasgow ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137121</th>\n",
       "      <td>slidcorabia.ro/administrator/includes/trulia/i...</td>\n",
       "      <td>bad</td>\n",
       "      <td>[slidcorabia, ro, administrator, includes, tru...</td>\n",
       "      <td>[slidcorabia, ro, administr, includ, trulia, i...</td>\n",
       "      <td>slidcorabia ro administr includ trulia index html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477173</th>\n",
       "      <td>youtube.com/watch?v=mZk3fOzKpQ4</td>\n",
       "      <td>good</td>\n",
       "      <td>[youtube, com, watch, v, mZk, fOzKpQ]</td>\n",
       "      <td>[youtub, com, watch, v, mzk, fozkpq]</td>\n",
       "      <td>youtub com watch v mzk fozkpq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212408</th>\n",
       "      <td>meds-zone.com/medic/drug/SUPER_C</td>\n",
       "      <td>good</td>\n",
       "      <td>[meds, zone, com, medic, drug, SUPER, C]</td>\n",
       "      <td>[med, zone, com, medic, drug, super, c]</td>\n",
       "      <td>med zone com medic drug super c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      URL Label  \\\n",
       "319744  education.com/schoolfinder/us/virginia/staffor...  good   \n",
       "351017  heraldscotland.com/sport/spl/aberdeen/glasgow-...  good   \n",
       "137121  slidcorabia.ro/administrator/includes/trulia/i...   bad   \n",
       "477173                    youtube.com/watch?v=mZk3fOzKpQ4  good   \n",
       "212408                   meds-zone.com/medic/drug/SUPER_C  good   \n",
       "\n",
       "                                           text_tokenized  \\\n",
       "319744  [education, com, schoolfinder, us, virginia, s...   \n",
       "351017  [heraldscotland, com, sport, spl, aberdeen, gl...   \n",
       "137121  [slidcorabia, ro, administrator, includes, tru...   \n",
       "477173              [youtube, com, watch, v, mZk, fOzKpQ]   \n",
       "212408           [meds, zone, com, medic, drug, SUPER, C]   \n",
       "\n",
       "                                             text_stemmed  \\\n",
       "319744  [educ, com, schoolfind, us, virginia, stafford...   \n",
       "351017  [heraldscotland, com, sport, spl, aberdeen, gl...   \n",
       "137121  [slidcorabia, ro, administr, includ, trulia, i...   \n",
       "477173               [youtub, com, watch, v, mzk, fozkpq]   \n",
       "212408            [med, zone, com, medic, drug, super, c]   \n",
       "\n",
       "                                            text_from_url  \n",
       "319744  educ com schoolfind us virginia stafford grace...  \n",
       "351017  heraldscotland com sport spl aberdeen glasgow ...  \n",
       "137121  slidcorabia ro administr includ trulia index html  \n",
       "477173                      youtub com watch v mzk fozkpq  \n",
       "212408                    med zone com medic drug super c  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phishing_urls.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585313ea",
   "metadata": {},
   "source": [
    "**CountVectorizer** is to convert the text data (URLs) into a numerical format that can be fed into machine learning models. This transformation allows the model to work with the frequency of words as features, which is essential for classification tasks like phishing detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8059cc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2c2549e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
       "\twith 3676066 stored elements and shape (549346, 350837)>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature = cv.fit_transform(phishing_urls.text_from_url)\n",
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3d8911f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature[:5].toarray()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
